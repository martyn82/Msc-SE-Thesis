\chapter{Conclusions}
\label{conclusions}

\subsubsection{\textit{\ref{itm:question_patterns}: \subQuestionOne}}
The patterns detected in this study using wavelet analysis on LOC signals
comprise similar sequences of LOC series within and across projects. The
waveforms of these patterns vary in all kinds of shapes. Type A patterns all
show a stagnation in LOC changes, that is, between very few and no changes
relative to the project size. Whereas types B, and AB patterns vary between
super-linear and sub-linear growth or decay (see Figure
\ref{figure:type_b_pattern}).

\subsubsection{\textit{\ref{itm:question_successfailure}: \subQuestionTwo}}
The events underlying the patterns vary widely and the event cannot directly be
derived from a pattern. A pattern is merely the symptom or result of an event.
Determining the event that caused the pattern requires an in-depth analysis of
the project and the time period comprising the pattern. Moreover, various
patterns may show similarities, but similar patterns often do not refer to the
same event.

\paragraph{}
In general, the ability to detect a pattern as being a group of similar
sequences within or across projects, depends on the similarity of the sequence
between other sequences within the same analysis. Therefore, it is important to
have a data set that is large enough and representative to the world of OSS
projects to be able to detect patterns that can be generalised as being warning
signs.

\paragraph{}
Another aspect that contributes to the success or failure of wavelet analysis
for software evolution is that the input signal should be free of gaps, as
discussed in section \ref{section:gapless_wavelets}. In the case an input LOC
signal for analysis is not continuous between the start and end boundaries of
the signal, the wavelet analysis will detect patterns that are not trustworthy,
and wavelet analysis may find more false-positive evolutionary events.

\paragraph{}
The classification of the patterns in this study was done to reduce the
number of patterns that may indicate warning signs. The chosen characteristics
for this classification influenced the reliability of finding warning signs.

Setting up stronger characteristics for the classification treats fewer
patterns as possible warning signs. This yields more false-negatives as some
warning signs might be missed.

On the contrary, setting up weaker characteristics for the classification treats
more patterns as possible warning signs which yields more false-positive
results.

\subsubsection{\textit{\ref{itm:question_warningsigns}: \researchQuestion}}
In this study, I have shown that wavelet analysis is able to find patterns that
increase the chances of a project to end as it appears that there is a relation
between a pattern of type A and the death of a project. However, this relation
was not found to be a causal relation.

Furthermore, as pointed out in the previous paragraphs, the patterns that were
found during analysis are subject to the data set as a whole. Although the data
set has a representative score that is sufficient, uniformly recognisable
patterns do not seem to exist. There always needs to be a context of
representative data to find patterns to a certain extent of reliability.

In this study, I present a classification of the patterns that could be a
warning sign, but it is still inconclusive that wavelet analysis is able to
find warning signs in OSS projects objectively.
