\chapter{Research method}
\label{method}

This chapter elaborates on the phases of the research, Data selection, Wavelet
transformation and analysis, Pattern identification, and Validation.

\section{Data selection}
\label{method:data}

The data for this research is provided by a tool by \citet{ohlohanalytics}.
This tool, ``\emph{OhlohAnalytics}\rm'', was developed as part of the
replicative research by \citet{bruntink2014}, and provides a validated and
cleansed data set of more than 10,000 OSS projects.

The projects are tracked by and gathered from Ohloh.net: \emph{``Ohloh is a
free, public directory of Free and Open Source Software and the contributors
who create and maintain it.'' }\rm \cite{ohloh}.

At the time of this writing, Ohloh tracks more than 660,000 OSS projects varying
in all ranges of size, and popularity. The most popular projects currently being
Apache HTTP Server, Apache OpenOffice, Apache Subversion, Bash, Firebug, Linux
Kernel, Mozilla Firefox, MySQL, PHP, and Ubuntu.

\subsection{Data validation and cleansing}
The OhlohAnalytics tool provides us with an initial data set of more than
10,000 OSS projects \cite{bruntink2014}. The raw data gathered from Ohloh
regularly contains errors and inconsistencies. This tool analyses the
consistency of the data and cleanses the data where needed. This results in a
consistent data set of project evolution data.



\subsection{Project selection criteria}

From the initial 10,000+ projects of which the evolution data is consistent, a
subset of 250 projects will be made. \citet{karus2013} used a data set of 27
projects to perform his wavelet analysis research. We believe a larger
data set will yield more trustworthy results. The number 250 is a somewhat
arbitrary number, but chosen to have a substantial larger set than the initial
study by \citeauthor{karus2013}, but still keep it feasible to analyse and
validate the data and results within the given time constaints of 4 months for
this thesis.

\subsubsection{Subsequent data series}
Prior to the selection of the projects for the study, another validation
step is needed. Although the set of 10,000+ projects' evolution data is
consistent, not all of it is suited for wavelet analysis.

To be able to perform wavelet analysis on any series of data, we need to have
a subsequent series (i.e., without gaps) of evolution data for each project
under study. Therefore, all the 10,000+ projects will be analysed for continuity
and only the projects that have a subsequent series of data are kept.

\subsubsection{Minimal sequence length}
A time series of 1 (monthly) data point is obviously not analysable over time
and uncomparable to larger projects. The threshold of at least 12 monthly data
points is chosen to minimise noise in the evolution data that may be caused by
too young and unstable projects.

\subsubsection{Representativeness}
Another criterion for the selection of projects in the data set is that they
form a subset that is representative to the set of all OSS projects tracked by
Ohloh.net. A tool created by \citet{nagappan} at Microsoft Research that is able
to determine the representativeness of a subset of projects will be used. This
tool scores projects by two metrics: total lines of code, and yearly
contributors count.

The tool by \citet{nagappan} is also capable of selecting a sample based on a
given baseline project and a total subset size. It keeps adding projects to the
subset as long as the project added will increase the total representativeness
of the sample subset to a given 'universe' of projects. We will use this tool
to select and score the sample subset of 250 projects using the Ohloh.net
projects as universe.



\section{Analysis}
The analysis of the projects under study will be conducted in three steps:
Wavelet transform, Similar sequence identification, and Similar sequence
grouping.

\subsection{Wavelet transform}
The first step in the analysis of time series of software evolution is the
wavelet transform. During this step discrete wavelet transform using the Haar
filter is applied on a project's signal. The results comprise the coefficients
at each level of decomposition. The results are saved for analysis.

\subsection{Similar sequence identification}
This second step takes the coefficients from the wavelet transform step and
analyses them to find \emph{similar sequences}\rm. A sequence is a subsequent
series of coefficients - resulted from discrete wavelet transform at a
particular level of decomposition - with a length between 3 and 65 points.
These thresholds were chosen to distinguish a sequence from an ordinary pair of
coefficients if the sequence is very short. On the contrary, if a sequence is
very long (larger than 65 points) we need to be able to distinguish the
sequence from the complete signal.

The 'points' mentioned here are not the same as data points in the data set.
The data points represent monthly data from a project, and the points in
sequences represent coefficients found at a certain level of decomposition
during the wavelet transform. More specifically, these 'points' are scaled or
filtered data points.

A sequence is considered 'similar' if the values of the compared sequences
deviate less than a threshold and if the sequence appears in at least 2 other
places. Similar sequences may be found within one project, but preferrably be
found across projects.

\subsection{Similar sequence grouping}
In this final wavelet analysis step, the similar sequences from previous step
are taken as input to find 'popular' sequences. A sequence is considered
'popular' if it appears at least 3 times in the sequence data. Each unique
sequence is assigned an identification number to be used in further analysis.
The popular sequences are grouped together and added meta data, such as, the
number of occurrances, the list of projects having the sequence, and whether it
appears in dead, alive, or both dead and alive projects.


\section{}



\section{Validation}

\begin{comment}
\section{Warning signs}
\subsection{Dead projects}
The validation of the sequence identification was done by first classifying
a subset of the data set containing only dead projects. A dead project is
defined as a project that had no change in LOC in the past 12 months.\\

The list of dead projects is then used to filter the sequences detected by
these dead projects. The resulting set of sequences contains just the sequences
in dead projects. Each sequence is related to other sequences in other projects
which might be dead or not. These related projects are evaluated by checking if
they exist in the dead projects list.

\subsection{Dying projects}
The related projects that are not 'dead' are extracted for analysis. Their
related sequences will be analyzed. If a project from the 'not-dead' list has a
sequence related to that of a 'dead' project, and the related sequence occurs
at the end of the non-dead project's evolution data, then that project is a
good candidate to be classified as a 'dying' project.\\

The resulting data set contains a list of projects that might be 'dying', the
transform level at which the sequence was detected, and the number of times the
sequence was matched against another sequence. This set is of use when manually
validating the projects.

\section{Validation}
To validate whether the 'dying' projects are indeed dying, a manual
investigation has to be made. For the resulting projects, the Ohloh.net project
page can be consulted. The data set used contains data until July 2013,
therefore, it is easy to confirm if the trend of 'dying' has continued up to
April 2014. The activity report at Ohloh.net is very useful. It tells the
amounts of commits and contributors in the past 30 days and in the past 12
months. Changes that show a decrease of over 30\% in either commits,
contributors, or both are in general a bad sign.
\end{comment}

\begin{comment}
This section describes the methods used to answer the research questions. A
good structure of this section often follows the sub questions by providing a
method for each.

The research method can be based on the “Scientific method”, but more creative
solutions could be defined as well. In any case, the method needs a thorough
motivation grounded in theory in order to be acceptable.

As part of the method a number of hypotheses are described. These hypotheses
will be tested by the research, using the methods described here.

An important part of this section is validation. How will you evaluate and
validate the outcomes of the research? You can look at Paul Klint’s homepage
for examples of this section as
well\footnote{http://homepages.cwi.nl/~paulk/thesesMasterSoftwareEngineering/2006/RichardKettelerij.pdf}.
\end{comment}