\chapter{Research method}
\label{method}

This chapter elaborates on the phases of the research, (1) data selection, (2)
wavelet analysis, (3) pattern identification, and (4) validation.

\section{Data selection}
\label{method:data}

For the gathering of data for this research, we use a tool by Magiel Bruntink
\cite{ohlohanalytics}. This tool, ``\emph{OhlohAnalytics}\rm'', was developed as
part of the replicative research by Magiel Bruntink \cite{bruntink2014}, and
provides a validated and cleansed data set of more than 10,000 OSS projects.

The projects are tracked by and gathered from
Ohloh\footnote{http://www.ohloh.net}: \emph{``Ohloh is a free, public directory
of Free and Open Source Software and the contributors who create and maintain
it.'' }\rm \cite{ohloh}.

Today, Ohloh tracks more than 660,000 OSS projects varying from tiny to huge,
and from very popular to unknown. The most popular projects being Apache HTTP
Server, Apache OpenOffice, Apache Subversion, Bash, Firebug, Linux Kernel,
Mozilla Firefox, MySQL, PHP, and Ubuntu.

\subsection{Data validation and cleansing}
The OhlohAnalytics tool provides us with an initial data set of more than
10,000 OSS projects \cite{bruntink2014}. The raw data gathered from Ohloh
regularly contains errors and inconsistencies. The tool helps with analysing
and cleansing this data, leaving a data set of project evolution data that is
consistent.



\subsection{Selection criteria}

From the initial 10,000+ projects of which the evolution data is consistent, a
subset of 250 projects will be made. Karus used a data set of 27 projects to
perform his wavelet analysis research \cite{karus2013}. We believe a larger
data set will yield more trustworthy results. The number 250 was chosen to have
a substantial larger set than the initial study by Karus, but still keep it
feasible to analyse and validate the data and results because of time
constaints.

\subsubsection{Continuous data sequence}
Before we can select the projects for the study, we need another validation
step. Although the set of 10,000+ projects' evolution data is consistent, not
all of it is useable for this study.

To be able to perform wavelet analysis on this data, we need to have a
continuous series (i.e., without gaps) of evolution data for each project under
study. Therefore, all the 10,000+ projects will be analysed by continuity and
only the projects that have a continuous series of data are kept.

\subsubsection{Minimal sequence length}
A time series of 1 monthly data point is obviously not analysable over time and
uncomparable to larger projects. The threshold of 12 monthly data points is
chosen to minimise noise in the evolution data that are caused by too young and
unstable projects.

\subsubsection{Sample selection}
Another criterion for the selection of projects in the data set is that they
form a subset that is representative to the set of all OSS projects tracked by
Ohloh. We use a tool created by Nagappan \emph{et al. }\rm\cite{nagappan} at
Microsoft Research that is able to determine the representativeness of a subset of
projects. The tool scores projects by the total lines of code and the 12-month
contributors count.

This tool is also capable of selecting that subset based on a given baseline
project and a total subset size. It keeps adding projects to the subset as long
as the project added will increase the total representativeness of the subset
to the given 'universe' of projects. We will use this tool to select and score
the subset of 250 projects from the Ohloh masterdata.



\section{Wavelet analysis}

\section{Pattern identification}

\section{Validation}

\begin{comment}
\section{Wavelets in software evolution}
The use of wavelet transformation in the analysis of software evolution removes
the factor of project size and enables comparing projects equally to find
similar sequences.

\paragraph{}
In software evolution, the signal can be any measurable property of an evolving
entity, such as team size, lines of code, number of commits, etc.
These properties can be measured at a given time series, such as age in months,
or even a non-time-related series such as lines of code. Measuring these
properties over the evolution of a project gives a series of signals. Software
repositories are a source of signals in software evolution. This allows wavelet
transform be applied directly for mining software repositories.

\section{Warning signs}
\subsection{Dead projects}
The validation of the sequence identification was done by first classifying
a subset of the data set containing only dead projects. A dead project is
defined as a project that had no change in LOC in the past 12 months.\\

The list of dead projects is then used to filter the sequences detected by
these dead projects. The resulting set of sequences contains just the sequences
in dead projects. Each sequence is related to other sequences in other projects
which might be dead or not. These related projects are evaluated by checking if
they exist in the dead projects list.

\subsection{Dying projects}
The related projects that are not 'dead' are extracted for analysis. Their
related sequences will be analyzed. If a project from the 'not-dead' list has a
sequence related to that of a 'dead' project, and the related sequence occurs
at the end of the non-dead project's evolution data, then that project is a
good candidate to be classified as a 'dying' project.\\

The resulting data set contains a list of projects that might be 'dying', the
transform level at which the sequence was detected, and the number of times the
sequence was matched against another sequence. This set is of use when manually
validating the projects.

\section{Validation}
To validate whether the 'dying' projects are indeed dying, a manual
investigation has to be made. For the resulting projects, the Ohloh.net project
page can be consulted. The data set used contains data until July 2013,
therefore, it is easy to confirm if the trend of 'dying' has continued up to
April 2014. The activity report at Ohloh.net is very useful. It tells the
amounts of commits and contributors in the past 30 days and in the past 12
months. Changes that show a decrease of over 30\% in either commits,
contributors, or both are in general a bad sign.
\end{comment}

\begin{comment}
This section describes the methods used to answer the research questions. A
good structure of this section often follows the sub questions by providing a
method for each.

The research method can be based on the “Scientific method”, but more creative
solutions could be defined as well. In any case, the method needs a thorough
motivation grounded in theory in order to be acceptable.

As part of the method a number of hypotheses are described. These hypotheses
will be tested by the research, using the methods described here.

An important part of this section is validation. How will you evaluate and
validate the outcomes of the research? You can look at Paul Klint’s homepage
for examples of this section as
well\footnote{http://homepages.cwi.nl/~paulk/thesesMasterSoftwareEngineering/2006/RichardKettelerij.pdf}.
\end{comment}