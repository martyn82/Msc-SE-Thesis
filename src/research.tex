\chapter{Research}
\label{research}

This chapter describes the execution of the research.

\section{Data set}
The data set of 250 projects was selected using the method described in section
\ref{method:data}. It was conducted in the steps described in the following
paragraphs.

\subsection{Initial analysis, validation, and cleansing}
The evolution data of a project is available as monthly data from Ohloh.net. The
raw data of 12,360 projects was collected from Ohloh.net in July 2013 by Magiel
Bruntink as part of his research \cite{bruntink2014}. It was then analysed,
validated, and cleansed accordingly by Bruntink's tool \emph{OhlohAnalytics}\rm
\cite{ohlohanalytics}.

This step consists of the analysis, validation, and cleansing of the data by
detecting inconsistent values and removing these records from the data set.
Additional fields are derived from and added to the raw data for convenience.

The complete list of data fields are shown in table \ref{table:fields}. The
column 'Source' specifies if the field is either 'Raw' data (i.e., directly
available from Ohloh), or if it is added by the OhlohAnalytics tool as derived
from an operation on one or more other fields. In the latter case, the fields
are listed. The 'lines of code' (LOC) metric is equal to the LOC metric used by
Ohloh. This is the total number of source lines of code at the given time of
analysis. These lines include all lines of source text for the project in any
programming language, but excludes blank lines and comments.

The result of this step is a consistent data set of evolution data of 10,811
projects.

\input{table_data_fields}

\subsection{Continuous data sequence}
The evolution data of the 10,811 projects contained gaps. Many projects do not
have a continuous series of evolution data. We expect a continuous series of
data to be required in order to analyse time series for a project. Therefore, a
number representing the continuity of the data was needed. For each project the
difference between the minimum and maximum values of the $age\_in\_months$ fact
is taken, added by one, giving us the expected number of data points a project
should have. The calculation of the fraction of total evolution data is done
for each project.

After the fractions of the total evolution data for each project are caculated,
we can filter these projects and keep only the projects that have all data points
between minimum and maximum $age\_in\_months$. From the set of 10,811 projects,
a total number of 6,418 projects is left.

\subsection{Minimal sequence length}
As a final step in validating and cleaning the master data set, we will be
keeping only the projects that have at least 12 data points (i.e., have a
subsequent evolution period of at least 1 year).

After this selection, a set of 5,986 projects is left where the sample will be
taken from.

\subsection{Sample selection}
For the selection of a sample of 250 projects, we use the tool created by
Nagappan \emph{et al. }\rm\cite{nagappan}. This tool takes a sample set and
selects additional projects to add to the sample that increase the overall
representativeness of that sample.

The tool iteratively selects 250 projects and adds it to the sample. Each
additional project is selected by its score to maximally increase the
representativeness of the sample as a whole, compared to the master data.

The master data is a list of 20,028 projects tracked by Ohloh.net delivered with
this tool. A pre-filtering of this master data was done to make the tool select
only the projects that appear in our data set of 5,986 projects. After
pre-filtering, a subset of the master data of 1,588 projects is left. From this
subset, a sample of 250 projects was selected.

The resulting sample of 250 projects was scored against the initial master data
of 20,028 projects and scores a 99.5\% representativeness.

\begin{comment}
\begin{table}
\centering
	\caption{Evolution signals}
	\begin{tabular}{| p{4cm} | p{4cm} | p{4cm} |}
	\hline
	\bfseries{Time domain}\rm & \bfseries{Frequency domain}\rm &
	\bfseries{Description}\rm
	\\
	\hline Age in months	& LOC & LOC per month. \\
							& Code Churn & Churn per month. \\
							& Active Developers & Contributors per month. \\ \hline
	\end{tabular}
\label{tab:series}
\end{table}

\section{Analysis}
The analysis is done in the following steps:
\begin{enumerate}
	\item Wavelet transform.
	\item Similar sequence identification.
	\item Similar sequence grouping.
\end{enumerate}

\subsection{Wavelet transform}
During the wavelet transform steps, each project is analyzed separately using
each combination as specified in table \ref{tab:series}.

The data is prepared by sorting it by the time domain, indexing, and aggregate
data where appropriate. Then the discrete wavelet transform is applied using the
Haar filter.

The resulting data structure is saved in a file representing the transform data
for a specific project. A file per coefficient (scale and filter) is saved
with aggregated data for all projects. These files contain all values per level
found for all projects.

\subsection{Similar sequence identification}
The results of the wavelet transforms are analyzed and identified as sequences.
A sequence is a series of values with a minimum length of 3 values and a maximum
length of 65. The sequences of each project are compared to the sequences of
every other project. In case a similar sequence is found, it is recorded.
Similar is having the same series of values with a maximum deviation of
0.005.

All found similar sequences are saved in a file per coefficient.

\subsection{Similar sequence grouping}
The similar sequence grouping step takes the similar sequences found in the
previous step and classifies the sequences by number of projects, number of
occurances, lengths, etc. The resulting file enables selection of sequences by
these properties. The resulting data is used for partial manual, and partial
automatic validation.
\end{comment}

\begin{comment}
This chapter reports on the execution of the research method as described in Chapter 3.

If the research has been divided into phases (e.g., using sub questions) the
phases are introduced, reported on and concluded individually. If needed this
Chapter could be split up to balance out the sizes of all Chapters.
An example Research Chapter is provided as Chapter 3 at Paulâ€™s home
page\footnote{http://homepages.cwi.nl/~paulk/thesesMasterSoftwareEngineering/2006/ReneWiegers.pdf}.
\end{comment}
