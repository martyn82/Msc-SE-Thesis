\chapter{Research}
\label{research}

\section{Data}
The evolution data of 250 OSS projects was gathered from
Ohloh.net\footnote{http://www.ohloh.net}. Ohloh is a project by the initiative
of Black Duck Software\footnote{http://www.blackducksoftware.com}. The Ohloh
universe contains approximately 600,000 open-source software projects in
January 2014. The evolution data of all these projects is tracked and monthly
analyzed by Ohloh.net.

\subsection{Data gathering}
The data was gathered using the tool \emph{OhlohAnalytics }\rm by Magiel
Bruntink \cite{ohlohanalytics}. The tool is created as part of the research
``\emph{An Initial Quality Analysis of the Ohloh Software Evolution Data}\rm''
by M. Bruntink. This tool provides us with an initial data set of more than
10,000 OSS projects gathered in July 2013.\\

\noindent
The following steps are done in the data gathering process:
\begin{enumerate}
	\item Data collection.
	\item Validation and cleaning.
\end{enumerate}

\subsubsection{Data collection}
During the data collection step the names of the projects tracked by Ohloh are
gathered. Then for each project, monthly analysis facts (so called
\emph{factoids}\rm) are gathered. These facts include: size facts (lines of code
(LOC), blank lines, commented lines), activity facts (number of commits, number
of contributors, LOC added/removed), enlistments (i.e., source code
repositories for the project), and programming languages.

\subsubsection{Validation and cleaning}
The initial validation step does sanity checks and filtering on the collected
data. It filters out the projects that have a wrongly configured repository,
has missing data, negative LOC added, negative LOC removed, negative LOC,
negative number of commits, negative number of contributors, or have
inconsistent values where the difference between the previous month and current
month numbers are inexplainable.\\

\noindent
The resulting set is a set of valid factoids for the 10,000 projects.

\subsection{Data selection}
The data selection procedure consists of the following steps:
\begin{enumerate}
	\item Project coverage computation.
	\item Master data filtering.
	\item Sample selection.
\end{enumerate}

\subsubsection{Project coverage computation}
The cleansed set of 10,000 projects is analyzed by computing the project's
evolution coverage. For each project, the difference between the minimum and
maximum age in months is taken against the number of months present in the
data set. This way, we have the percentage of the coverage between the mininum
and maximum age.

\subsubsection{Master data filtering}
The next step is to filter out the projects from the master data that do not
have a 100\% coverage or that have less than 12 data points (months). The result
of this step is a filtered master data set that is the input of the next step.

\subsubsection{Sample selection}
A sample of 250 projects need to be selected from the 10,000 projects gathered
by the OhlohAnalytics tool. This sample must be a representative selection of
the projects tracked by Ohloh.net. For this selection process the tool
\emph{SampleSoftwareProjects }\rm was used. The SampleSoftwareProjects tool was
developed for the research by Nagappan et al. at Microsoft Research
\cite{nagappan}.

\paragraph{}
The tool takes the filtered master data set containing facts of interest about
the projects tracked by Ohloh.net to characterize these projects. These facts
include activity facts (user count, average rating, last updated), project age,
size facts (LOC), and language facts. The projects are given a score by each of
these dimensions. Taking one sample project as base line the script evaluates
projects from the master set and adds them to the sample if it increases the
overall coverage to be close to that of the master set as a whole. The
resulting data set is aimed to be 100\% representative.

\paragraph{}
For this study we took the project \emph{Mozilla Firefox }\rm as basis for
the sample. The resulting data set of 250 projects has a representativeness of
100\% of the Ohloh.net universe, according to the SampleSoftwareProjects tool.

\section{Metrics}
The following metrics are used and measured monthly:

\begin{description}
	\item[Age in months] \hfill \\
		This is the number of months since the first factoid of a project.

	\item[Active developers] \hfill \\
		At Ohloh.net this is called the number of contributors and is the actual
		number of developers that have made at least one commit in the month of the
		factoid.
	
	\item[Lines of code (LOC)] \hfill \\
		For this study we use the same definition of LOC as in the original study by
		Karus; blank lines and commented lines are also included in the LOC counts.
		The reason for this is that we want to be able to measure activity and a
		comment added or removed is also considered project activity related to code.

	\item[Code Churn] \hfill \\
		Is the sum of LOC added, LOC removed, and LOC modified. The modified LOC is
		not tracked at Ohloh.net. Modified LOC is aggregated in LOC added and LOC
		removed; a modified LOC is basically a line that is both removed and added.

\end{description}

\noindent
The variable we used in the time domain is 'Age in months'; in the
frequency domain this is 'LOC', 'Code Churn', and 'Active Developers'. Table
\ref{tab:series} shows which variable in the time domain is plotted against
what variable in the frequency domain.

\begin{table}
\centering
	\caption{Evolution signals}
	\begin{tabular}{| p{4cm} | p{4cm} | p{4cm} |}
	\hline
	Time domain & Frequency domain & Description \\ \hline
	Age in months   & LOC & LOC per month. \\
					& Code Churn & Churn per month. \\
					& Active Developers & Contributors per month. \\ \hline
	\end{tabular}
\label{tab:series}
\end{table}

\section{Analysis}
The analysis is done in the following steps:
\begin{enumerate}
	\item Wavelet transform.
	\item Similar sequence identification.
	\item Similar sequence grouping.
\end{enumerate}

\subsection{Wavelet transform}
During the wavelet transform steps, each project is analyzed separately using
each combination as specified in table \ref{tab:series}.

The data is prepared by sorting it by the time domain, indexing, and aggregate
data where appropriate. Then the discrete wavelet transform is applied using the
Haar filter.

The resulting data structure is saved in a file representing the transform data
for a specific project. A file per coefficient (scale and filter) is saved
with aggregated data for all projects. These files contain all values per level
found for all projects.

\subsection{Similar sequence identification}
The results of the wavelet transforms are analyzed and identified as sequences.
A sequence is a series of values with a minimum length of 3 values and a maximum
length of 65. The sequences of each project are compared to the sequences of
every other project. In case a similar sequence is found, it is recorded.
Similar is having the same series of values with a maximum deviation of
0.005.

All found similar sequences are saved in a file per coefficient.

\subsection{Similar sequence grouping}
The similar sequence grouping step takes the similar sequences found in the
previous step and classifies the sequences by number of projects, number of
occurances, lengths, etc. The resulting file enables selection of sequences by
these properties. The resulting data is used for partial manual, and partial
automatic validation.

\section{Warning signs}
\subsection{Dead projects}
The validation of the sequence identification was done by first classifying
a subset of the data set containing only dead projects. A dead project is
defined as a project that had no change in LOC in the past 12 months.\\

The list of dead projects is then used to filter the sequences detected by
these dead projects. The resulting set of sequences contains just the sequences
in dead projects. Each sequence is related to other sequences in other projects
which might be dead or not. These related projects are evaluated by checking if
they exist in the dead projects list.

\subsection{Dying projects}
The related projects that are not 'dead' are extracted for analysis. Their
related sequences will be analyzed. If a project from the 'not-dead' list has a
sequence related to that of a 'dead' project, and the related sequence occurs
at the end of the non-dead project's evolution data, then that project is a
good candidate to be classified as a 'dying' project.\\

The resulting data set contains a list of projects that might be 'dying', the
transform level at which the sequence was detected, and the number of times the
sequence was matched against another sequence. This set is of use when manually
validating the projects.

\section{Validation}
To validate whether the 'dying' projects are indeed dying, a manual
investigation has to be made. For the resulting projects, the Ohloh.net project
page can be consulted. The data set used contains data until July 2013,
therefore, it is easy to confirm if the trend of 'dying' has continued up to
April 2014. The activity report at Ohloh.net is very useful. It tells the
amounts of commits and contributors in the past 30 days and in the past 12
months. Changes that show a decrease of over 30\% in either commits,
contributors, or both are in general a bad sign.

\begin{comment}
This chapter reports on the execution of the research method as described in Chapter 3.

If the research has been divided into phases (e.g., using sub questions) the
phases are introduced, reported on and concluded individually. If needed this
Chapter could be split up to balance out the sizes of all Chapters.
An example Research Chapter is provided as Chapter 3 at Paulâ€™s home
page\footnote{http://homepages.cwi.nl/~paulk/thesesMasterSoftwareEngineering/2006/ReneWiegers.pdf}.
\end{comment}
